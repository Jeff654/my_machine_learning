{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_breast_cancer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-182dc2810290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcance_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcance_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcance_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_breast_cancer' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "cance_data = load_breast_cancer()\n",
    "train_data = cance_data.data\n",
    "train_label = cance_data.target\n",
    "print(len(train_data), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 114 455 114\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, random_state=0, test_size=0.2)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数：给予重要参数一个初始值(意义不太大)，只是为了方便确定其他参数(便于调参)\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\", \n",
    "    \"objective\": \"binary\", \n",
    "    \"metric\": \"auc\", \n",
    "    \"nthread\": 4, \n",
    "    \"learning_rate\": 0.1, \n",
    "    \"num_leaves\": 30, \n",
    "    \"max_depth\": 5, \n",
    "    \"subsample\": 0.8, \n",
    "    \"colsample_bytree\": 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n_estimates:  188\nbest cv score:  0.9913471629808542\n"
     ]
    }
   ],
   "source": [
    "# step1: 确定学习率和迭代次数\n",
    "data_train = lgb.Dataset(X_train, y_train)\n",
    "cv_results = lgb.cv(params, data_train, num_boost_round=1000, nfold=5, \n",
    "                    stratified=False, shuffle=True, metrics=\"auc\", \n",
    "                    early_stopping_rounds=50, seed=0)\n",
    "print(\"best n_estimates: \", len(cv_results[\"auc-mean\"]))\n",
    "print(\"best cv score: \", pd.Series(cv_results[\"auc-mean\"]).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_leaves': 10, 'max_depth': 4} 0.9943573667711598\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果，选取 n_estimates = 188\n",
    "# step2: 确定 max_depth 和 num_leaves\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_test1 = {\n",
    "    \"max_depth\": range(3, 8, 1), \n",
    "    \"num_leaves\": range(5, 100, 5)\n",
    "}\n",
    "model = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                           objective=\"binary\", \n",
    "                           metrics=\"auc\", \n",
    "                           learning_rate=0.1, \n",
    "                           n_estimators=188, \n",
    "                           max_depth=6, \n",
    "                           bagging_fraction=0.8, \n",
    "                           feature_fraction=0.8)\n",
    "gsearch1 = GridSearchCV(estimator=model, param_grid=params_test1, \n",
    "                        scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "print(gsearch1.best_params_, gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_data_in_leaf': 51, 'max_bin': 15} 0.9952978056426331\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果可知，选取 max_depth = 4, num_leaves = 10\n",
    "# step3: 确定 min_data_in_leaf 和 max_bin 参数\n",
    "params_test2 = {\n",
    "    \"max_bin\": range(5, 256, 10), \n",
    "    \"min_data_in_leaf\": range(1, 102, 10)\n",
    "}\n",
    "model2 = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                            objective=\"binary\", \n",
    "                            metrics=\"auc\", \n",
    "                            learning_rate=0.1, \n",
    "                            n_estimators=188, \n",
    "                            max_depth=4, \n",
    "                            num_leaves=10, \n",
    "                            bagging_fraction=0.8, \n",
    "                            feature_fraction=0.8)\n",
    "gsearch2 = GridSearchCV(estimator=model2, param_grid=params_test2, \n",
    "                        scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "print(gsearch2.best_params_, gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bagging_freq': 0, 'feature_fraction': 0.8, 'bagging_fraction': 0.1} 0.9952978056426331\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果，选取 min_data_in_leaf = 51, max_bin = 15\n",
    "# step4: 确定 feature_fraction, bagging_fraction, bagging_freq\n",
    "params_test3 = {\n",
    "    \"feature_fraction\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], \n",
    "    \"bagging_fraction\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"bagging_freq\": range(0, 100, 10)\n",
    "}\n",
    "model3 = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                            objective=\"binary\", \n",
    "                            metrics=\"auc\", \n",
    "                            learning_rate=0.1, \n",
    "                            n_estimators=188, \n",
    "                            max_depth=4, \n",
    "                            num_leaves=10, \n",
    "                            max_bin=15, \n",
    "                            min_data_in_leaf=51)\n",
    "gsearch3 = GridSearchCV(estimator=model3, param_grid=params_test3, \n",
    "                        scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "print(gsearch3.best_params_, gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 1e-05, 'lambda_l2': 1e-05} 0.9952978056426331\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果，选取 bagging_freq = 0, feature_fraction = 0.8, bagging_fraction = 0.1\n",
    "# step5: 确定 lambda_l1 和 lambda_l2\n",
    "params_test4 = {\n",
    "    \"lambda_l1\": [1e-5, 1e-3, 1e-1, 0.0, 0.3, 0.5, 0.7, 0.9, 1.0], \n",
    "    \"lambda_l2\": [1e-5, 1e-3, 1e-1, 0.0, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "model4 = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                            objective=\"binary\", \n",
    "                            metrics=\"auc\", \n",
    "                            learning_rate=0.1, \n",
    "                            n_estimators=188, \n",
    "                            max_depth=4, \n",
    "                            num_leaves=10, \n",
    "                            max_bin=15, \n",
    "                            min_data_in_leaf=51, \n",
    "                            bagging_fraction=0.6, \n",
    "                            bagging_freq=0, \n",
    "                            feature_fraction=0.8)\n",
    "gsearch4 = GridSearchCV(estimator=model4, param_grid=params_test4, \n",
    "                        scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "gsearch4.fit(X_train, y_train)\n",
    "print(gsearch4.best_params_, gsearch4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_split_gain': 0.0} 0.9952978056426331\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果， 选取 lambda_l1 = 1e-5, lambda_l2 = 1e-5\n",
    "# step6: 确定 min_split_gain\n",
    "params_test5 = {\n",
    "    \"min_split_gain\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "model5 = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                            objective=\"binary\", \n",
    "                            metrics=\"auc\", \n",
    "                            learning_rate=0.1, \n",
    "                            n_estimators=188, \n",
    "                            max_depth=4, \n",
    "                            num_leaves=10, \n",
    "                            max_bin=15, \n",
    "                            min_data_in_leaf=51, \n",
    "                            bagging_fraction=0.6, \n",
    "                            bagging_freq=0, \n",
    "                            feature_fraction=0.8, \n",
    "                            lambda_l1=1e-5, \n",
    "                            lambda_l2=1e-5)\n",
    "gsearch5 = GridSearchCV(estimator=model5, param_grid=params_test5, \n",
    "                        scoring=\"roc_auc\", cv=5, n_jobs=-1)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "print(gsearch5.best_params_, gsearch5.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9736842105263158\nauc:  0.9744363289933311\n"
     ]
    }
   ],
   "source": [
    "# 根据上述结果，选取 min_split_gain = 0.0\n",
    "# step7: 降低学习率，增加迭代次数，验证模型\n",
    "from sklearn import metrics\n",
    "final_model = lgb.LGBMClassifier(boosting_type=\"gbdt\", \n",
    "                                 objective=\"binary\", \n",
    "                                 metrics=\"auc\", \n",
    "                                 learning_rate=0.01, \n",
    "                                 n_estimators=1000, \n",
    "                                 max_depth=4, \n",
    "                                 num_leaves=10, \n",
    "                                 max_bin=15, \n",
    "                                 min_data_in_leaf=51, \n",
    "                                 bagging_fraction=0.6, \n",
    "                                 bagging_freq=0, \n",
    "                                 feature_fraction=0.8, \n",
    "                                 lambda_l1=1e-5, \n",
    "                                 lambda_l2=1e-5, \n",
    "                                 min_split_gain=0.0)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(\"acc: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"auc: \", metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default acc:  0.9649122807017544\ndefault auc:  0.9637980311209908\n"
     ]
    }
   ],
   "source": [
    "# 使用默认参数\n",
    "default_model = lgb.LGBMClassifier()\n",
    "default_model.fit(X_train, y_train)\n",
    "y_pred = default_model.predict(X_test)\n",
    "print(\"default acc: \", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"default auc: \", metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}