# -*- coding: utf-8 -*-


import numpy as np
import matplotlib.pyplot as plt
from sklearn import svm, datasets

iris = datasets.load_iris()

# fetch the first two features
x = iris.data[:, :2]
y = iris.target

# step size in the mesh
h = 0.02

# SVM regularization parameter
C = 1.0

svc = svm.SVC(kernel = 'linear', C = C).fit(x, y)
rbf_svc = svm.SVC(kernel = 'sigmoid', gamma = 0.7, C = C).fit(x, y)
poly_svc = svm.SVC(kernel = 'poly', degree = 3, C = C).fit(x, y)
lin_svc = svm.LinearSVC(C = C).fit(x, y)

# create a mesh to plot
x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1
y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1

xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

titles = ['SVC with linear kernel', 'LinearSVC (linear kernel)', 'SVC with RBF kernel', 'SVC with polynomial (degree = 3) kernel']


for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):
	# plot the decision boundary
	plt.subplot(2, 2, i + 1)
	plt.subplots_adjust(wspace = 0.4, hspace = 0.4)

	z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

	# put the result into a color plot
	z = z.reshape(xx.shape)
	plt.contour(xx, yy, z, cmap = plt.cm.Paired, alpha = 0.8)

	# plot the training data
	plt.scatter(x[:, 0], x[:, 1], c = y, cmap = plt.cm.Paired)
	plt.xlabel('Sepal length')
	plt.ylabel('Sepal width')
	plt.xlim(xx.min(), xx.max())
	plt.ylim(yy.min(), yy.max())
	plt.xticks(())
	plt.yticks(())
	plt.title(titles[i])
plt.show()

